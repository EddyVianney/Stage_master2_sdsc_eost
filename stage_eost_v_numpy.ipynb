{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99eda386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from datetime import date, datetime\n",
    "import datetime\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.feature_selection import f_regression\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.manifold import TSNE\n",
    "from DBCV import DBCV\n",
    "import hdbscan\n",
    "import csv\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import operator\n",
    "import math\n",
    "from dtaidistance import dtw\n",
    "import seaborn as sns\n",
    "import elevation\n",
    "import json\n",
    "plt.style.use('fivethirtyeight')\n",
    "from osgeo import gdal \n",
    "from subprocess import Popen\n",
    "import simplekml\n",
    "import copy\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy.ma as ma\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc211b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    \n",
    "    def __init__(self, data_path, filename1, filename2, pc=0.3):\n",
    "        self.load(data_path, filename1, filename2, pc)\n",
    "        \n",
    "    def set_latitudes(self, latitudes):\n",
    "        self.latitudes = latitudes\n",
    "        \n",
    "    def set_longitudes(self, longitudes):\n",
    "        self.longitudes = longitudes\n",
    "        \n",
    "    def set_topo(self, topo):\n",
    "        self.topo = topo\n",
    "        \n",
    "    def set_ns_mean_velocities(self, velocities):\n",
    "        self.ns_mean_velocities = velocities\n",
    "        \n",
    "    def set_ew_mean_velocities(self, velocities):\n",
    "        self.ew_mean_velocities = velocities\n",
    "    \n",
    "    def set_dates(self, dates):\n",
    "        self.dates = dates\n",
    "    \n",
    "    def set_ns_displacements(self, ns_displacements):\n",
    "        self.ns_displacements = ns_displacements\n",
    "        \n",
    "    def set_ew_displacements(self, ew_displacements):\n",
    "        self.ew_displacements = ew_displacements\n",
    "        \n",
    "    def load(self,  data_path, filename1, filename2, pc):\n",
    "        ns_displacements, ew_displacements, booleans = [], [], []\n",
    "        ns_infos, ns = self.load_component(data_path, filename1)\n",
    "        ew_infos, ew = self.load_component(data_path, filename2)\n",
    "        m = len(ns[0])\n",
    "        \n",
    "        for n, components in enumerate(zip(ns, ew)):\n",
    "            if ns[n].isnull().sum().sum() / m < pc:\n",
    "                ns_displacements.append(components[0].interpolate(limit_direction='both', inplace=False)['displacement'].values)\n",
    "                ew_displacements.append(components[1].interpolate(limit_direction='both', inplace=False)['displacement'].values)\n",
    "                booleans.append(False)\n",
    "            else:\n",
    "                booleans.append(True)\n",
    "            \n",
    "        self.set_latitudes(ma.array(ns_infos['Lat'].values, mask = booleans).compressed())\n",
    "        self.set_longitudes(ma.array(ns_infos['Lon'].values, mask = booleans).compressed())\n",
    "        self.set_topo(ma.array(ns_infos['Topo'].values, mask = booleans).compressed())\n",
    "        self.set_ns_mean_velocities(ma.array(ns_infos['Vel'].values, mask = booleans).compressed())\n",
    "        self.set_ew_mean_velocities(ma.array(ew_infos['Vel'].values, mask = booleans).compressed())\n",
    "        self.set_ns_displacements(np.array(ns_displacements))\n",
    "        self.set_ew_displacements(np.array(ew_displacements))\n",
    "        self.set_dates(ns[0].index)\n",
    "        \n",
    "    #np.count_nonzero(np.isnan(data))\n",
    "    def load_image_correlation(self, data_path, ns_fi, ew_filename):\n",
    "        df_ns, df_ns_ts = self.load_component(data_path, ns_filename)\n",
    "        df_ew, df_ew_ts = self.load_component(data_path, ew_filename)\n",
    "        df_ew.rename(columns={'Vel': 'Vel_ew'}, inplace=True)\n",
    "        df_ns.rename(columns={'Vel': 'Vel_ns'}, inplace=True)\n",
    "        geo = pd.concat([df_ew[['id', 'Lat','Lon','Topo','Vel_ew']], df_ns[['Vel_ns']]], axis=1)\n",
    "        return geo, df_ns_ts, df_ew_ts\n",
    "        \n",
    "    def load_component(self, data_path, filename):\n",
    "        \n",
    "        # numéro de la ligne ou commence les données\n",
    "        num_start = 44\n",
    "        # numéro de la ligne ou se trouve la liste des dates\n",
    "        num_list_dates = 40\n",
    "        # attributs présent dans les données\n",
    "        columns = ['id', 'Lat','Lon', 'Topo', 'Vel', 'Coer',' CosN', 'CosE', 'CosU']\n",
    "        # dictionnaire stockant les données\n",
    "        data = {column: [] for column in columns}\n",
    "        # liste des dates \n",
    "        indexes = []\n",
    "        # series temporelles\n",
    "        series = []\n",
    "        # liste de dataframes\n",
    "        df_series = []\n",
    "        \n",
    "        with open(data_path + '/' + filename) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=\",\")\n",
    "            line_count = 1 \n",
    "            for row in csv_reader:\n",
    "                if line_count == num_list_dates:\n",
    "                    indexes = [row[0].split(' ')[1]] + row[1:]\n",
    "                if line_count >= num_start:\n",
    "                    # extraction des premiers attributs\n",
    "                    for i in range(len(columns)):\n",
    "                        data[columns[i]].append(row[i])\n",
    "                    # extraction de l'attribut TS(série temporelle)\n",
    "                    series.append([float(v) for v in row[len(columns):]])\n",
    "                line_count  += 1\n",
    "            if len(indexes) != len(series[0]):\n",
    "                print('Erreur : Les indexes et les valeurs ne correspondent pas')\n",
    "            # convertir les index en date\n",
    "            indexes = [d.strip()[0:8] for d in indexes]\n",
    "            # créer une liste de dataframes, chacun contenant une série temporelle\n",
    "            for serie in series:\n",
    "                tmp_serie = pd.DataFrame({'displacement': pd.Series(serie, index=pd.DatetimeIndex(indexes))})\n",
    "                tmp_serie.sort_index(inplace=True)\n",
    "                df_series.append(tmp_serie)\n",
    "            # creer un dataframe pour les autres attributs\n",
    "            df = pd.DataFrame(data)\n",
    "            for column in df.columns:\n",
    "                df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "            df.set_index('id')\n",
    "        return df, df_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78935272",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Displacement():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def compute_velocity(self, displacement):\n",
    "        return 0\n",
    "    \n",
    "    def test(self):\n",
    "        return 0\n",
    "    \n",
    "    def is_mean_velocity_significant(self, displacements, days):\n",
    "        # extraire X et y\n",
    "        X = StandardScaler().fit_transform(displacements)\n",
    "        # calculer la p-value de la regression lineaire\n",
    "        _, pval = f_regression(X, days)\n",
    "        return  pval[0]\n",
    "    \n",
    "    def compute_inst_vel(self, displacements, dates):\n",
    "        diff_displacements, durations = self.prepare(displacements, dates)\n",
    "        return np.divide(diff_displacements, durations)\n",
    "    \n",
    "    # TODO\n",
    "    def is_stationary(self, displacement, alpha, freq='D'):\n",
    "        resampled = displacement.resample(freq)\n",
    "        interpolated = upsampled.interpolate(method='linear')\n",
    "        return self.compute_adfuller(interpolated) < alpha\n",
    "    \n",
    "     # TODO\n",
    "    def smooth(self, displacement, factor):\n",
    "        std = math.sqrt(serie.var())\n",
    "        for i in range(len(serie)):\n",
    "            if abs(serie.iloc[i].displacement) > ampl*std:\n",
    "                serie.iloc[i, serie.columns.get_loc('displacement')]= np.nan\n",
    "        return serie.interpolate(limit_direction='both', inplace=False)\n",
    "    \n",
    "    def prepare(self, displacement, dates):\n",
    "        durations = np.diff(dates) / np.timedelta64(1,'D')\n",
    "        return self.transform_displacement(displacement), self.transform_date(dates)\n",
    "    \n",
    "    def transform_date(self, dates):\n",
    "        temp = np.diff(np.array(dates))\n",
    "        shifted = np.array([np.timedelta64(1, 'D') for n in range(temp.shape[0])])\n",
    "        shifted[0:-1] = temp[1:]\n",
    "        return (shifted + temp)[:-1] / np.timedelta64(1,'D')\n",
    "    \n",
    "    def transform_displacement(self, displacement):\n",
    "        temp = np.diff(np.array(displacement))\n",
    "        shifted = np.zeros(temp.shape[0])\n",
    "        shifted[0:-1] = temp[1:]\n",
    "        return np.add(temp, shifted)[:-1]\n",
    "    \n",
    "    def transform_dates_for_lnreg(self, dates):\n",
    "        lnr_dates = np.cumsum( np.diff(data.dates) /  np.timedelta64(1,'D') )\n",
    "        return np.insert(lnr_dates, 0, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc75f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFromImageCorrelation():\n",
    "    \n",
    "    def __init__(self, data, raster_folder_name, dem_filename, pc=0.4, alpha=0.05, ref='wgs84'):\n",
    "        self.data  = data\n",
    "        self.compute_slope_map(raster_folder_name, dem_filename)\n",
    "        self.compute_vlm_std()\n",
    "        self.n_cores = multiprocessing.cpu_count()\n",
    "        self.pc = pc\n",
    "        self.ref = ref\n",
    "        self.alpha = alpha\n",
    "        self.velocities = []\n",
    "        self.mask = np.array([])\n",
    "    \n",
    "    def compute_vel(self, ns_component, ew_component):\n",
    "        return math.sqrt(ns_component * ns_component + ew_component * ew_component)\n",
    "    \n",
    "    def is_ns_mean_velocity_significant(self, n):\n",
    "        displacement = self.data.ns_displacements[n].reshape(-1, 1)\n",
    "        dates = Displacement().transform_dates_for_lnreg(self.data.dates)\n",
    "        return Displacement().is_mean_velocity_significant(displacement, dates) < self.alpha\n",
    "    \n",
    "    def is_ew_mean_velocity_significant(self, n):\n",
    "        displacement = self.data.ew_displacements[n].reshape(-1, 1)\n",
    "        dates = Displacement().transform_dates_for_lnreg(self.data.dates)\n",
    "        return Displacement().is_mean_velocity_significant(displacement, dates) < self.alpha\n",
    "    \n",
    "    def is_mean_velocity_significant(self, n):\n",
    "        return self.is_ns_mean_velocity_significant(n) and self.is_ew_mean_velocity_significant(n)\n",
    "    \n",
    "    def is_moving(self, n, factor):\n",
    "        ns_vel = data.ns_mean_velocities[n]\n",
    "        ew_vel = data.ew_mean_velocities[n]\n",
    "        return self.compute_vel(ns_vel, ew_vel) > factor * self.sigma\n",
    "    \n",
    "    def filter_by(self, factor, min_slope=5):\n",
    "        vfunc = np.vectorize(self.is_to_select)\n",
    "        self.mask = vfunc(np.arange(self.data.latitudes.shape[0]), factor, min_slope)\n",
    "\n",
    "    def is_to_select(self, n, factor, min_slope):\n",
    "        return (self.is_moving(n, factor) and\n",
    "               self.is_ns_mean_velocity_significant(n) and\n",
    "                self.is_ew_mean_velocity_significant(n))\n",
    "    \n",
    "    def filter_by_linear_reg(self):\n",
    "        pass\n",
    "                \n",
    "    def compute_vlm_std(self):\n",
    "        vfunc = np.vectorize(self.compute_vel)\n",
    "        ns_velocities = self.data.ns_mean_velocities\n",
    "        ew_velocities = self.data.ew_mean_velocities\n",
    "        self.sigma = np.std(vfunc(ns_velocities, ew_velocities))\n",
    "        \n",
    "    def compute_inst_vels(self, series):\n",
    "        with multiprocessing.Pool(self.n_cores) as p:\n",
    "            results = p.map(Displacement().compute_inst_vel, series)\n",
    "            return results\n",
    "        \n",
    "    def compute_velocities(self):\n",
    "        if self.mask.shape[0] > 0:\n",
    "            ns_displacements = self.data.ns_displacements[~np.array(self.mask)]\n",
    "            ew_displacements = self.data.ew_displacements[~np.array(self.mask)]\n",
    "            ns_vels = self.compute_inst_vels(ns_displacements)\n",
    "            ew_vels = self.compute_inst_vels(ew_displacements)\n",
    "            vfunc = np.vectorize(self.compute_vel)\n",
    "            self.velocities = np.array([vfunc(ns, ew) for ns, ew in zip(ns_displacements, ew_displacements)])\n",
    "                    \n",
    "    def set_slope_map_path(self, slope_map_path):\n",
    "        self.slope_map_path = slope_map_path\n",
    "        \n",
    "    def load_raster(self, raster_folder_name, raster_filename):\n",
    "        return gdal.Open(raster_folder_name + '/' +  raster_filename)\n",
    "        \n",
    "    def compute_slope_map(self, raster_folder_name, dem_name):\n",
    "        dem = None\n",
    "        slope_map = None\n",
    "        slope_map_name = dem_name.split('.')[0] + '_' + 'slope_map.tif'\n",
    "        slope_map_path = raster_folder_name + '/' + slope_map_name\n",
    "        if not os.path.isfile(slope_map_path):\n",
    "            dem = gdal.Open(raster_folder_name + '/'+ dem_name)\n",
    "            slope_map = gdal.DEMProcessing(slope_map_path, dem, 'slope', computeEdges = True)\n",
    "        self.set_slope_map_path(slope_map_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db25a6c",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ebd41",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d396b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH  = './donnees' \n",
    "filename1  = 'MM_TIO_NS_31TGK_20151227_to_20200906.csv'\n",
    "filename2  = 'MM_TIO_EW_31TGK_20151227_to_20200906.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dce0130c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ec6097a7b745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-69036a66025b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path, filename1, filename2, pc)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_latitudes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatitudes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-69036a66025b>\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, data_path, filename1, filename2, pc)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mns_displacements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mew_displacements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbooleans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mns_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mew_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-69036a66025b>\u001b[0m in \u001b[0;36mload_component\u001b[0;34m(self, data_path, filename)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# créer une liste de dataframes, chacun contenant une série temporelle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mserie\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mtmp_serie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'displacement'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0mtmp_serie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mdf_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_serie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, freq, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_extract_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         dtarr = DatetimeArray._from_sequence_not_strict(\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36m_from_sequence_not_strict\u001b[0;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_infer_freq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         subarr, tz, inferred_freq = sequence_to_dt64ns(\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36msequence_to_dt64ns\u001b[0;34m(data, dtype, copy, tz, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m         \u001b[0;31m# e.g. list, tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1933\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1934\u001b[0m             \u001b[0;31m# i.e. generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mndim\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mndim\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   3136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m     \"\"\"\n\u001b[0;32m-> 3138\u001b[0;31m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = Data(DATA_PATH, filename1, filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5e309",
   "metadata": {},
   "source": [
    "## Calcul des profils de vitesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a3ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_folder_path = 'rasters'\n",
    "dem_filename =  '31TGK_copernicus_dem.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_correlation = DataFromImageCorrelation(data, raster_folder_path, dem_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "523f77dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015833768879708388"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_correlation.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15bc4fea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_correlation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ccb67625407b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_correlation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_correlation' is not defined"
     ]
    }
   ],
   "source": [
    "img_correlation.filter_by(factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "03bd4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_disp_ns_ew(ns_ts, ew_ts):\n",
    "\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(15,10))\n",
    "\n",
    "        ax[0].plot(ns_ts, color='blue', label='displacement (m)', marker='o', linewidth=2)\n",
    "        ax[0].set_title('NS cumulative displacement')\n",
    "        ax[0].set_xlabel('time')\n",
    "        ax[0].set_ylabel('displacement')\n",
    "        ax[0].legend()\n",
    "\n",
    "        ax[1].plot(ew_ts, color='orange', label='displacement (m)', marker='o', linewidth=2)\n",
    "        ax[1].set_title('EW cumulative displacement')\n",
    "        ax[1].set_xlabel('time')\n",
    "        ax[1].set_ylabel('displacement')\n",
    "        ax[1].legend()\n",
    "        plt.savefig('displacement.png')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81377fb",
   "metadata": {},
   "source": [
    "## Analyse en composantes princpales(PCA) et décomposition en composantes indépendantes (ICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "23df7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "8f743d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = None\n",
    "pca = PCA(n_components=n_components, random_state=0)\n",
    "ica = FastICA(n_components=n_components, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "14835b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_decomposition(data, n_components=20, tol=0.005, random_state=0):\n",
    "    \n",
    "    sources_ica = compute_ica_decomposition(data)\n",
    "    sources_pca = compute_pca_decomposition(data)\n",
    "    \n",
    "    return sources_ica, sources_pca\n",
    "\n",
    "def compute_ica_decomposition(data, n_components=20, tol=0.005, random_state=0):\n",
    "    \n",
    "    # normalisation des données\n",
    "    X = normalize(data).T\n",
    "    \n",
    "    # décomposition en composantes indépendantes (ICA)\n",
    "    ica = FastICA(n_components=n_components, random_state=random_state, tol=tol)\n",
    "    sources_ica = ica.fit_transform(X)\n",
    "    \n",
    "    return sources_ica\n",
    "\n",
    "def compute_pca_decomposition(data, n_components=20, tol=0.005, random_state=0):\n",
    "    \n",
    "    # normalisation des données\n",
    "    X = normalize(data).T\n",
    "    \n",
    "     # décompositions en composantes principales (PCA)\n",
    "    pca = PCA(n_components=n_components, random_state=random_state)\n",
    "    sources_pca = pca.fit_transform(X)\n",
    "    \n",
    "    return sources_pca\n",
    "\n",
    "def plot_components(data, output, ncols=3, colormap='tab20', figsize=(25,15)):\n",
    "    n = data.shape[1]\n",
    "    nrows = int(n / ncols) if n % ncols == 0 else int(math.ceil(n / ncols))\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "    cmap = plt.get_cmap(colormap)\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, n)]\n",
    "    for i in range(n):\n",
    "        axes[int(i / ncols), i % ncols].plot(data[:, i], color=colors[i])\n",
    "        axes[int(i / ncols), i % ncols].set_title('component %d' % (i+1))\n",
    "    plt.savefig(output + '.png')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "e978f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_sources_ica = compute_ica_decomposition(data.ns_displacements, n_components=20)\n",
    "ew_sources_ica = compute_ica_decomposition(data.ew_displacements, n_components=20)\n",
    "ns_sources_pca = compute_pca_decomposition(data.ns_displacements, n_components=20)\n",
    "ew_sources_pca = compute_pca_decomposition(data.ew_displacements, n_components=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23290f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_components(ns_sources_ica, 'ns_ica')\n",
    "plot_components(ew_sources_ica, 'ew_ica')\n",
    "plot_components(ns_sources_pca, 'ns_pca')\n",
    "plot_components(ew_sources_pca, 'ew_pca')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ec5d15",
   "metadata": {},
   "source": [
    "# Sélection des sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a683938",
   "metadata": {},
   "source": [
    "# Remarques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab91e2",
   "metadata": {},
   "source": [
    "* les deux méthodes ne renvoient pas la même amplitude \n",
    "* amplitude plus faible avec ICA\n",
    "* les sources avec PCA sont obtenues dans la base orthogonal formée par les composantes principales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1052632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_kml_file(latitudes, longitudes, color, kml=None, filename='visualization', generate=True):\n",
    "    \n",
    "    url = 'http://maps.google.com/mapfiles/ms/micons/'\n",
    "    kml = simplekml.Kml()\n",
    "    for n, coords in enumerate(zip(latitudes, longitudes)):\n",
    "        pnt = kml.newpoint(description=str(n), coords=[(coords[0], coords[1])])\n",
    "        pnt.iconstyle.icon.href = url + color + '-dot.png'\n",
    "    if generate:\n",
    "        kml.save(filename + '.kml')\n",
    "        return  None\n",
    "    else:\n",
    "        return kml\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f12816",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_kml_file(data.latitudes, data.longitudes,'green', 'geo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
